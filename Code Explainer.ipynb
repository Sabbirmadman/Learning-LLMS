{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## First Import the necessary pkages\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9D8PFSBs23pG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYADI2we4Avq",
        "outputId": "2aea2299-4c5a-4a73-bcfb-728de101f175"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.17.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
            "Downloading groq-0.17.0-py3-none-any.whl (109 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/109.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.8/109.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "EjHve6bJ2oSV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import json\n",
        "from typing import List\n",
        "from bs4 import BeautifulSoup\n",
        "from IPython.display import Markdown, display, update_display\n",
        "from openai import OpenAI #if you wanna use open ai\n",
        "from groq import Groq #if you wanna use GroqCloud for free models like llama\n",
        "from IPython.display import Markdown, display #This is for viasualising the markdown format"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the groq or open ai api key from Secrets"
      ],
      "metadata": {
        "id": "D35oiTQH3k5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key = userdata.get('GROQ_API_KEY')\n",
        "# userdata.get('OPEN_AI_API_KEY')\n",
        "\n",
        "# Check the key\n",
        "if not api_key:\n",
        "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
        "else:\n",
        "    print(\"API key found and looks good so far!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_Zv_xtf222q",
        "outputId": "9de31cac-d048-4984-ec22-a01cc63d8a6f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API key found and looks good so far!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# constants for groq i am using lama 70b model\n",
        "MODEL_GPT = 'gpt-4o-mini'\n",
        "MODEL_LLAMA = 'llama-3.3-70b-versatile'"
      ],
      "metadata": {
        "id": "gRxkoNAm31Vp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Chat Clients for the models"
      ],
      "metadata": {
        "id": "0_WRk01t41FL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = Groq(api_key=api_key)\n",
        "# client = OpenAI(api_key=api_key)\n",
        "\n",
        "#check if the client sends a response\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL_LLAMA,\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3ySRUNV40oC",
        "outputId": "fa8c58fb-1f2e-440d-acf1-6693bc0d9d07"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Los Angeles Dodgers won the 2020 World Series, defeating the Tampa Bay Rays in the series 4 games to 2. It was the Dodgers' first World Series title since 1988. The series was played from October 20 to October 27, 2020, at Globe Life Field in Arlington, Texas, due to the COVID-19 pandemic.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now using prompting style we will define User prompt and system prompt.\n",
        "A **system prompt** tells the model what is it and how should it reply where **user prompt** means based on what query the model should reply.\n"
      ],
      "metadata": {
        "id": "yjT_qdKl6kIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"You are an assistant that analyzes code provided by a user and explain the code\n",
        "line by line so that its very easy to understand for the user. Respond in markdown.\"\"\"\n",
        "user_prompt = \"\"\"\n",
        "Please explain what this code does and why:\n",
        "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "kr8P2qhD7G5M"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lets see it in action\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL_LLAMA,\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt},\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Z9c3h0VV5Odg",
        "outputId": "a71e3b9e-0ae6-4ecb-bdb8-796608989356"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Explanation of the Code\n",
            "```python\n",
            "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
            "```\n",
            "Let's break down the code line by line:\n",
            "\n",
            "#### 1. `yield from` Statement\n",
            "*   The `yield from` statement is used in Python to yield items from an iterable.\n",
            "*   It's a way to delegate part of the iteration to a sub-generator.\n",
            "\n",
            "#### 2. `{...}` Set Comprehension\n",
            "*   The `{...}` is a set comprehension, which is similar to a list comprehension but creates a set instead of a list.\n",
            "*   Sets in Python are unordered collections of unique elements.\n",
            "\n",
            "#### 3. `book.get(\"author\") for book in books`\n",
            "*   This is a loop within the set comprehension that iterates over each `book` in the `books` collection.\n",
            "*   The `book.get(\"author\")` call attempts to retrieve the value associated with the key `\"author\"` from each `book`.\n",
            "*   The `.get()` method is used instead of directly accessing the key (`book[\"author\"]`) to avoid a `KeyError` if the key is missing.\n",
            "*   If the key is missing, `.get()` returns `None` by default.\n",
            "\n",
            "#### 4. `if book.get(\"author\")`\n",
            "*   This is a conditional statement within the set comprehension that filters out books that do not have an author.\n",
            "*   If `book.get(\"author\")` returns a truthy value (i.e., the author is present), the expression is included in the set; otherwise, it's skipped.\n",
            "\n",
            "### Why This Code is Useful\n",
            "This code is useful when you have a list of books and you want to extract a set of unique authors from these books. It:\n",
            "\n",
            "*   Avoids duplicate authors by using a set.\n",
            "*   Handles cases where a book might not have an author.\n",
            "*   Uses a generator expression (`yield from`) to efficiently yield the authors one by one, which is beneficial for large collections of books.\n",
            "\n",
            "Here's an example of how this code might be used within a function:\n",
            "```python\n",
            "def get_unique_authors(books):\n",
            "    \"\"\"Yield unique authors from a list of books.\"\"\"\n",
            "    yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
            "\n",
            "# Example usage\n",
            "books = [\n",
            "    {\"title\": \"Book1\", \"author\": \"Author1\"},\n",
            "    {\"title\": \"Book2\", \"author\": \"Author2\"},\n",
            "    {\"title\": \"Book3\"},\n",
            "    {\"title\": \"Book4\", \"author\": \"Author1\"},\n",
            "]\n",
            "\n",
            "unique_authors = get_unique_authors(books)\n",
            "for author in unique_authors:\n",
            "    print(author)\n",
            "```\n",
            "This would output:\n",
            "```\n",
            "Author1\n",
            "Author2\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 912
        },
        "collapsed": true,
        "id": "hqRALT-98yyY",
        "outputId": "0d648dd4-6fbd-4cb3-81f5-254098d8d2ef"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Explanation of the Code\n```python\nyield from {book.get(\"author\") for book in books if book.get(\"author\")}\n```\nLet's break down the code line by line:\n\n#### 1. `yield from` Statement\n*   The `yield from` statement is used in Python to yield items from an iterable.\n*   It's a way to delegate part of the iteration to a sub-generator.\n\n#### 2. `{...}` Set Comprehension\n*   The `{...}` is a set comprehension, which is similar to a list comprehension but creates a set instead of a list.\n*   Sets in Python are unordered collections of unique elements.\n\n#### 3. `book.get(\"author\") for book in books`\n*   This is a loop within the set comprehension that iterates over each `book` in the `books` collection.\n*   The `book.get(\"author\")` call attempts to retrieve the value associated with the key `\"author\"` from each `book`.\n*   The `.get()` method is used instead of directly accessing the key (`book[\"author\"]`) to avoid a `KeyError` if the key is missing.\n*   If the key is missing, `.get()` returns `None` by default.\n\n#### 4. `if book.get(\"author\")`\n*   This is a conditional statement within the set comprehension that filters out books that do not have an author.\n*   If `book.get(\"author\")` returns a truthy value (i.e., the author is present), the expression is included in the set; otherwise, it's skipped.\n\n### Why This Code is Useful\nThis code is useful when you have a list of books and you want to extract a set of unique authors from these books. It:\n\n*   Avoids duplicate authors by using a set.\n*   Handles cases where a book might not have an author.\n*   Uses a generator expression (`yield from`) to efficiently yield the authors one by one, which is beneficial for large collections of books.\n\nHere's an example of how this code might be used within a function:\n```python\ndef get_unique_authors(books):\n    \"\"\"Yield unique authors from a list of books.\"\"\"\n    yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n\n# Example usage\nbooks = [\n    {\"title\": \"Book1\", \"author\": \"Author1\"},\n    {\"title\": \"Book2\", \"author\": \"Author2\"},\n    {\"title\": \"Book3\"},\n    {\"title\": \"Book4\", \"author\": \"Author1\"},\n]\n\nunique_authors = get_unique_authors(books)\nfor author in unique_authors:\n    print(author)\n```\nThis would output:\n```\nAuthor1\nAuthor2\n```"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lets modularise the code"
      ],
      "metadata": {
        "id": "OS3MkaU--E_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"You are an assistant that analyzes code provided by a user and explain the code\n",
        "line by line so that its very easy to understand for the user. Respond in markdown.\"\"\""
      ],
      "metadata": {
        "id": "VGXhWbR0-oGR"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def user_prompt_generator(code_snippets: str) -> str:\n",
        "    return f\"\"\"\n",
        "    Please explain what this code does and why:\n",
        "    {code_snippets}\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "dKZ1xhkf9CUo"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def messages_for(code_snippets: str) -> str:\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt_generator(code_snippets)}\n",
        "    ]"
      ],
      "metadata": {
        "id": "c8ijTxY7-nF3"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def code_analyzer(MODEL: str, code_snippets: str ) -> str:\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages = messages_for(code_snippets)\n",
        "    )\n",
        "    bot_response =  response.choices[0].message.content\n",
        "    display(Markdown(bot_response))"
      ],
      "metadata": {
        "id": "nzR356Jd-907"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this will reply as chat gpt stream output\n",
        "def code_analyzer_stream_output(MODEL: str, code_snippets: str ) -> str:\n",
        "    stream = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages = messages_for(code_snippets),\n",
        "        stream=True\n",
        "    )\n",
        "    response = \"\"\n",
        "    display_handle = display(Markdown(\"\"), display_id=True)\n",
        "    for chunk in stream:\n",
        "        response += chunk.choices[0].delta.content or ''\n",
        "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
        "        update_display(Markdown(response), display_id=display_handle.display_id)"
      ],
      "metadata": {
        "id": "GDXNB1uzAPQi"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "userInput = input(\"Enter the code snippet you want to analyze: \")\n",
        "code_analyzer(MODEL_LLAMA, userInput)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "AR6POYyk_O--",
        "outputId": "4268f9cd-352d-4921-e566-2d3f9067bb04"
      },
      "execution_count": 39,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the code snippet you want to analyze: headers = {  \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\" }  class Website:      def __init__(self, url):         \"\"\"         Create this Website object from the given url using the BeautifulSoup library         \"\"\"         self.url = url         response = requests.get(url, headers=headers)         soup = BeautifulSoup(response.content, 'html.parser')         self.title = soup.title.string if soup.title else \"No title found\"         for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):             irrelevant.decompose()         self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Code Explanation\n#### Importing Libraries and Setting User Agent\n```python\nheaders = {  \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\" }\n```\nThis line sets a dictionary `headers` with a `\"User-Agent\"` key. The value of this key is a string that identifies the browser and operating system of the client making the HTTP request. This is done to mimic the behavior of a real web browser and avoid being blocked by websites that don't want to be scraped.\n\n#### Defining the Website Class\n```python\nclass Website:\n```\nThis line defines a new class called `Website`.\n\n#### Initializing the Website Object\n```python\ndef __init__(self, url):\n```\nThis is the constructor method of the `Website` class, which is called when an object of this class is instantiated. The `url` parameter is the URL of the website that the object will represent.\n\n#### Docstring for the Constructor Method\n```python\n\"\"\"Create this Website object from the given url using the BeautifulSoup library\"\"\"\n```\nThis is a docstring that provides a description of the constructor method. It explains that the method creates a `Website` object from a given URL using the BeautifulSoup library.\n\n#### Sending an HTTP Request and Getting the Response\n```python\nself.url = url\nresponse = requests.get(url, headers=headers)\n```\nHere, the `url` attribute of the `Website` object is set to the provided `url`. Then, an HTTP GET request is sent to the specified `url` with the previously defined `headers`. The response from the server is stored in the `response` variable.\n\n#### Parsing the HTML Content\n```python\nsoup = BeautifulSoup(response.content, 'html.parser')\n```\nThe HTML content of the response is parsed using the `BeautifulSoup` library, which creates a parse tree that can be used to extract data from the HTML.\n\n#### Extracting the Title of the Website\n```python\nself.title = soup.title.string if soup.title else \"No title found\"\n```\nThis line extracts the title of the website from the parse tree. If the website has a title, it is stored in the `title` attribute of the `Website` object. If no title is found, the string \"No title found\" is stored instead.\n\n#### Removing Irrelevant Elements from the Parse Tree\n```python\nfor irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n    irrelevant.decompose()\n```\nThis loop goes through all the elements in the body of the HTML that are of type `script`, `style`, `img`, or `input`. These elements are considered irrelevant because they do not contain text that is visible to the user. The `decompose` method is used to remove these elements from the parse tree.\n\n#### Extracting the Text from the Parse Tree\n```python\nself.text = soup.body.get_text(separator=\"\\n\", strip=True)\n```\nFinally, this line extracts the text from the parse tree, excluding any irrelevant elements that were removed in the previous step. The `separator` parameter is set to `\\n` to separate the text with newline characters, and the `strip` parameter is set to `True` to remove any leading or trailing whitespace from the text. The extracted text is stored in the `text` attribute of the `Website` object.\n\n### Why This Code is Useful\nThis code is useful for scraping websites and extracting relevant information from them. By removing irrelevant elements like scripts, styles, images, and input fields, it makes it easier to extract the actual text content of a website. This can be useful for tasks like text analysis, sentiment analysis, or data mining. Additionally, by setting a User-Agent header, the code can avoid being blocked by websites that don't want to be scraped."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "userInput = input(\"Enter the code snippet you want to analyze: \")\n",
        "code_analyzer_stream_output(MODEL_LLAMA, userInput)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zxML9LpaApsE",
        "outputId": "61d9448f-8850-4fa1-8134-e4cd939c9c83"
      },
      "execution_count": 43,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the code snippet you want to analyze: def stream_brochure(company_name, url):     stream = Groqclient.chat.completions.create(         model=MODEL,         messages=[             {\"role\": \"system\", \"content\": system_prompt},             {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}           ],         stream=True     )          response = \"\"     display_handle = display(Markdown(\"\"), display_id=True)     for chunk in stream:         response += chunk.choices[0].delta.content or ''         response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")         update_display(Markdown(response), display_id=display_handle.display_id)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Code Explanation\n#### Function Definition\npython\ndef stream_brochure(company_name, url):\n\nThis line defines a function named `stream_brochure` that takes two parameters: `company_name` and `url`.\n\n#### Initialization of Stream\npython\nstream = Groqclient.chat.completions.create(\n\nHere, the function `stream_brochure` is using the `Groqclient` library to create a stream of completions. The `Groqclient` library is likely an API client for a language model or chat service.\n\n#### Stream Configuration\npython\nmodel=MODEL,\nmessages=[\n    {\"role\": \"system\", \"content\": system_prompt},\n    {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n],\nstream=True\n\nIn this section, the function is configuring the stream with the following settings:\n* `model`: The language model to use for generating completions. The `MODEL` variable is not defined in this snippet, but it's likely a pre-trained model.\n* `messages`: A list of messages to use as input for the language model. The list contains two messages:\n\t+ The first message is a system prompt, which is a predefined string stored in the `system_prompt` variable.\n\t+ The second message is a user prompt generated by the `get_brochure_user_prompt` function, which takes `company_name` and `url` as input.\n* `stream=True`: This setting enables streaming mode, which allows the function to receive a continuous stream of completions from the language model.\n\n#### Response Initialization\npython\nresponse = \"\"\ndisplay_handle = display(Markdown(\"\"), display_id=True)\n\nHere, the function initializes an empty string `response` to store the generated completion. It also creates a display handle using the `display` function from a library like Jupyter Notebook or a similar environment. The display handle is used to update the output in real-time.\n\n#### Streaming Completions\npython\nfor chunk in stream:\n    response += chunk.choices[0].delta.content or ''\n\nThis loop iterates over the stream of completions generated by the language model. For each chunk, it extracts the content of the first choice (i.e., the most likely completion) and appends it to the `response` string.\n\n#### Response Processing\npython\nresponse = response.replace(\"\",\"\").replace(\"\", \"\")\n\nHere, the function processes the `response` string by removing backticks (`` ` ``) and the string \"\".\n\n#### Updating Display\npython\nupdate_display(Markdown(response), display_id=display_handle.display_id)\n\nFinally, the function updates the display using the `update_display` function, passing the processed `response` string as Markdown content and the display ID from the display handle. This updates the output in real-time, allowing the user to see the generated completion as it is being generated.\n\n### Why This Code Exists\nThis code is likely part of a larger application that uses a language model to generate content, such as a brochure, based on a company name and URL. The `stream_brochure` function is designed to generate this content in real-time, using a streaming API to receive a continuous stream of completions from the language model. The function processes the generated content, removes unwanted characters, and updates the display in real-time, allowing the user to see the generated brochure as it is being generated."
          },
          "metadata": {}
        }
      ]
    }
  ]
}